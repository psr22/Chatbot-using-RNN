{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Question & Answer Bot Project\n",
    "\n",
    "## Project Overview\n",
    "In this project, we implement a chatbot that can answer questions based on a \"story\" given to the bot.\n",
    "\n",
    "We are using a subset of the BaBi dataset released by Facebook research. https://research.fb.com/downloads/babi.\n",
    "There are 10,000 data in the training set and 1,000 data in the testing set. Each data in the training/testing set consists of 3 components:\n",
    "> - Story - consists of single or multiple sentences\n",
    "> - Question - single sentence query related to the story\n",
    "> - Answer - \"yes\" or \"no\" answer to the question\n",
    "\n",
    "The model for our chatbot is a RNN network with attention mechanism. It includes the following layers: Embedding, LSTM, Dropout, Dense and Activation. The design of the model pretty much follows the idea in the paper \"End-to-End Memory Networks\": https://arxiv.org/pdf/1503.08895.pdf. \n",
    "\n",
    "Our model achieved pretty high accuary on training/testing set and performs really good on run time generated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read as binary\n",
    "with open('train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read as binary\n",
    "with open('test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))\n",
    "print(type(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train data:  10000\n",
      "Length of the test data:  1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the train data: \", len(train_data))\n",
    "print(\"Length of the test data: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Mary',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'journeyed',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.'],\n",
       "  ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       "  'no'),\n",
       " (['Mary',\n",
       "   'moved',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bathroom',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'journeyed',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'back',\n",
       "   'to',\n",
       "   'the',\n",
       "   'hallway',\n",
       "   '.'],\n",
       "  ['Is', 'Daniel', 'in', 'the', 'bathroom', '?'],\n",
       "  'no')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train_data is a list of tuples consist of 3 parts: story, question, answer.\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'journeyed',\n",
       " 'moved',\n",
       " 'the',\n",
       " 'to'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from all stories and questions\n",
    "vocab = set()\n",
    "\n",
    "for story, question, answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual length of the vocabulary:  37\n"
     ]
    }
   ],
   "source": [
    "# Add one to length of vocabulary: Keras embedding layer requires this.\n",
    "vocab_len = len(vocab) + 1\n",
    "print(\"Actual length of the vocabulary: \", vocab_len-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of all the stories\n",
    "all_story_len = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get maximum of the stories\n",
    "max_story_len = max(all_story_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of the stories:  156\n",
      "Maximum length of the question:  6\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum length of the stories: \", max_story_len)\n",
    "print(\"Maximum length of the question: \", max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'back': 1,\n",
       " 'down': 2,\n",
       " '.': 3,\n",
       " 'daniel': 4,\n",
       " 'got': 5,\n",
       " 'the': 6,\n",
       " 'in': 7,\n",
       " 'put': 8,\n",
       " 'hallway': 9,\n",
       " 'apple': 10,\n",
       " '?': 11,\n",
       " 'office': 12,\n",
       " 'went': 13,\n",
       " 'yes': 14,\n",
       " 'left': 15,\n",
       " 'up': 16,\n",
       " 'john': 17,\n",
       " 'journeyed': 18,\n",
       " 'moved': 19,\n",
       " 'milk': 20,\n",
       " 'is': 21,\n",
       " 'garden': 22,\n",
       " 'picked': 23,\n",
       " 'there': 24,\n",
       " 'took': 25,\n",
       " 'football': 26,\n",
       " 'dropped': 27,\n",
       " 'mary': 28,\n",
       " 'sandra': 29,\n",
       " 'bathroom': 30,\n",
       " 'bedroom': 31,\n",
       " 'travelled': 32,\n",
       " 'kitchen': 33,\n",
       " 'discarded': 34,\n",
       " 'to': 35,\n",
       " 'grabbed': 36,\n",
       " 'no': 37}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question, answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Mary',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Daniel',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hallway',\n",
       "  '.']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train_story_text is a list of lists of words\n",
    "train_story_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_story_seq))\n",
    "print(len(train_story_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Mary',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.',\n",
       "  'Daniel',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hallway',\n",
       "  '.']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[28, 19, 35, 6, 30, 3, 29, 18, 35, 6, 31, 3],\n",
       " [28,\n",
       "  19,\n",
       "  35,\n",
       "  6,\n",
       "  30,\n",
       "  3,\n",
       "  29,\n",
       "  18,\n",
       "  35,\n",
       "  6,\n",
       "  31,\n",
       "  3,\n",
       "  28,\n",
       "  13,\n",
       "  1,\n",
       "  35,\n",
       "  6,\n",
       "  31,\n",
       "  3,\n",
       "  4,\n",
       "  13,\n",
       "  1,\n",
       "  35,\n",
       "  6,\n",
       "  9,\n",
       "  3]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_seq[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our own list of list of word indicies with padding.\n",
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len, max_question_len=max_question_len):\n",
    "    # Stories = X\n",
    "    X = []\n",
    "    \n",
    "    # Questions = Xq\n",
    "    Xq = []\n",
    "    \n",
    "    # Y Correct Answer ['yes', 'no']\n",
    "    Y = []\n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # for each story\n",
    "        # [23, 14, 15]\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        y = np.zeros(len(word_index)+1)\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)   # X holds list of lists of word indices for stories.\n",
    "        Xq.append(xq) # Xq holds list of lists for word indices for questions.\n",
    "        Y.append(y) # Y holds lists of lists of (38) biniary numbers, only 1 of them is 1.\n",
    "        \n",
    "    return (pad_sequences(X, maxlen=max_story_len), pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 30,  5, 31],\n",
       "       [ 0,  0,  0, ..., 30, 32, 31],\n",
       "       [ 0,  0,  0, ..., 30, 32, 31],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 30, 23, 31],\n",
       "       [ 0,  0,  0, ..., 30, 32, 31],\n",
       "       [ 0,  0,  0, ..., 23, 26, 31]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 497 of the questions have answer 'yes', 503 of the questions have answer 'no'.\n",
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms and Techniques\n",
    "\n",
    "The design in this project follows the paper \"End-to-End Memory Networks\" https://arxiv.org/pdf/1503.08895.pdf\n",
    "\n",
    "Below are the detail descriptions about the algorithms and techniques used in this model (quoted from that paper):\n",
    "\n",
    "**Single Layer:**\n",
    "<img src=\"images/end_to_end_networks_descriptions.GIF\" style=\"width:500;height:500px;\">\n",
    "\n",
    "<img src=\"images/end_to_end_networks_diagram3.GIF\" style=\"width:500;height:500px;\">\n",
    "\n",
    "Source of the above figure: https://arxiv.org/pdf/1503.08895.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of the model\n",
    "\n",
    "The architecture of the model implemented below follows the paper: The https://arxiv.org/pdf/1503.08895.pdf\n",
    "\n",
    "The layers of the model looks like:\n",
    "1. Input\n",
    "> - A. input_sequence (fits on input_train): shape = (batch_size, max_story_len))\n",
    "> - B. question (fits on queries_train: shape = (batch_size, max_query_len))\n",
    "2. Embedding\n",
    "> - A. embedding for input_encoder_m: take input from input_sequence. Output shape: (batch_size, story_maxlen, embedding_dim)\n",
    "> - B. embedding for input_encoder_c: take input from input_sequence. Output shape: (batch_size, story_maxlen, max_question_len)\n",
    "> - C. embedding for question_encoder: take input from question. Output shape: (batch_size, query_maxlen, embedding_dim)\n",
    "3. Layers after Embedding\n",
    "> - A. dot: dot input_encoded_m and question_encoded (output from 2A and 2C) along axes of embedding dimension. Output shape: (batch_size, story_maxlen, query_maxlen)\n",
    "> - B. add: add output from 3A and 2B. Output shape: (batch_size, story_maxlen, query_maxlen)\n",
    "> - C. Permute: permute 2nd and 3rd axes from output of 3B. Output shape: (batch_size, query_maxlen, story_maxlen)\n",
    "> - D. concatenate: concatenate output from 3C and 2B. Output shape: (batch_size, query_maxlen, story_maxlen+embedding_dim) \n",
    "4. LSTM (hidden_unit = 32)\n",
    "5. Dropout (rate = 0.3)\n",
    "6. Dense (output = vocab_size)\n",
    "7. Activation (activation function = 'softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER shape=(max_story_len, batch_size)\n",
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_len\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT ENCODER M\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# OUTPUT\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT ENCODER C\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "# OUTPUT\n",
    "# (samples, story_maxlen, max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "# OUTPUT\n",
    "# (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODED <---- ENCODER(INPUT)\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "# input_encoded_m: (batch_size, story_maxlen, embedding_dim)\n",
    "# input_encoded_c: (batch_size, story_maxlen, query_maxlen)\n",
    "# question_encoded: (batch_size, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 156, 64)\n",
      "(?, 6, 64)\n"
     ]
    }
   ],
   "source": [
    "print(input_encoded_m.shape)\n",
    "print(question_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m, question_encoded], axes=(2,2)) # why axes is (2,2) ==> dot product along the embedding dim (64 numbers dot 64 numbers)\n",
    "match = Activation('softmax')(match)\n",
    "\n",
    "# NOTE: match after dot: (batch_size, story_maxlen, query_maxlen)\n",
    "# match after Activation: (batch_size, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: match (after dot): (batch_size, story_maxlen, query_maxlen)!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match, input_encoded_c]) # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2,1))(response) # (samples, query_maxlen, story_maxlen)\n",
    "\n",
    "# response after add: (batch_size, story_maxlen, query_maxlen)\n",
    "# response after Permute: (batch_size, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: response after Permute: (batch_size, query_maxlen, story_maxlen)!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response, question_encoded])\n",
    "\n",
    "# Note: answer: (batch_size, query_maxlen, story_maxlen+embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer\n",
    "# Note: answer: (batch_size, query_maxlen, story_maxlen+embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: answer (after concatenate): (batch_size, query_maxlen, story_maxlen+embedding_dim)!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer) #(samples, 32)\n",
    "# answer: (batch_size, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32)\n"
     ]
    }
   ],
   "source": [
    "print(answer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)\n",
    "# answer: (batch_size, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dense(vocab_size)(answer) # (samples, vocab_size) # YES/NO 0000\n",
    "# answer (batch_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation('softmax')(answer)\n",
    "# answer: (batch_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_2/Softmax:0' shape=(?, 38) dtype=float32>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence, question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 1.0238 - acc: 0.4941 - val_loss: 0.7043 - val_acc: 0.4970\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.7187 - acc: 0.5034 - val_loss: 0.6980 - val_acc: 0.5030\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.7055 - acc: 0.4947 - val_loss: 0.6958 - val_acc: 0.4970\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.7004 - acc: 0.4948 - val_loss: 0.6955 - val_acc: 0.4970\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.6988 - acc: 0.4958 - val_loss: 0.6943 - val_acc: 0.4970\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.6977 - acc: 0.5006 - val_loss: 0.6937 - val_acc: 0.5030\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.6961 - acc: 0.5066 - val_loss: 0.6944 - val_acc: 0.4970\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6968 - acc: 0.4965 - val_loss: 0.6934 - val_acc: 0.5030\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6957 - acc: 0.5014 - val_loss: 0.6933 - val_acc: 0.4970\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6955 - acc: 0.5025 - val_loss: 0.6935 - val_acc: 0.4970\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6956 - acc: 0.5044 - val_loss: 0.6934 - val_acc: 0.5030\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6957 - acc: 0.4966 - val_loss: 0.6944 - val_acc: 0.4970\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6959 - acc: 0.4919 - val_loss: 0.6935 - val_acc: 0.4970\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6953 - acc: 0.4996 - val_loss: 0.6944 - val_acc: 0.4970\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6957 - acc: 0.4974 - val_loss: 0.6938 - val_acc: 0.5030\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6950 - acc: 0.4960 - val_loss: 0.6934 - val_acc: 0.4970\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6953 - acc: 0.5016 - val_loss: 0.6944 - val_acc: 0.4970\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6953 - acc: 0.4909 - val_loss: 0.6939 - val_acc: 0.5030\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6953 - acc: 0.5032 - val_loss: 0.6931 - val_acc: 0.5030\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6952 - acc: 0.4959 - val_loss: 0.6950 - val_acc: 0.5030\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6946 - acc: 0.5027 - val_loss: 0.6947 - val_acc: 0.4970\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6951 - acc: 0.4954 - val_loss: 0.6942 - val_acc: 0.4970\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6953 - acc: 0.4947 - val_loss: 0.6945 - val_acc: 0.5030\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6948 - acc: 0.4987 - val_loss: 0.6932 - val_acc: 0.5030\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6946 - acc: 0.5045 - val_loss: 0.6944 - val_acc: 0.4970\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6952 - acc: 0.4960 - val_loss: 0.6934 - val_acc: 0.5030\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6924 - acc: 0.5144 - val_loss: 0.6890 - val_acc: 0.5330\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6707 - acc: 0.5596 - val_loss: 0.6588 - val_acc: 0.5520\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6424 - acc: 0.6009 - val_loss: 0.6224 - val_acc: 0.6700\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.5555 - acc: 0.7251 - val_loss: 0.4561 - val_acc: 0.7950\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.4588 - acc: 0.8035 - val_loss: 0.4186 - val_acc: 0.8200\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.4120 - acc: 0.8318 - val_loss: 0.3791 - val_acc: 0.8360\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3853 - acc: 0.8447 - val_loss: 0.3821 - val_acc: 0.8400\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3575 - acc: 0.8565 - val_loss: 0.3655 - val_acc: 0.8390: 0\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3548 - acc: 0.8563 - val_loss: 0.3638 - val_acc: 0.8360\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3435 - acc: 0.8585 - val_loss: 0.3618 - val_acc: 0.8370\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3418 - acc: 0.8581 - val_loss: 0.3572 - val_acc: 0.8350\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3325 - acc: 0.8605 - val_loss: 0.3604 - val_acc: 0.8310\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3326 - acc: 0.8617 - val_loss: 0.3494 - val_acc: 0.8410\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3239 - acc: 0.8641 - val_loss: 0.3535 - val_acc: 0.8440\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3224 - acc: 0.8651 - val_loss: 0.3616 - val_acc: 0.8320\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.3213 - acc: 0.8641 - val_loss: 0.3570 - val_acc: 0.8410\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.3135 - acc: 0.8672 - val_loss: 0.3502 - val_acc: 0.8410\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3119 - acc: 0.8663 - val_loss: 0.3456 - val_acc: 0.8380\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3095 - acc: 0.8638 - val_loss: 0.3495 - val_acc: 0.8380\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3094 - acc: 0.8664 - val_loss: 0.3513 - val_acc: 0.8460\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3114 - acc: 0.8660 - val_loss: 0.3448 - val_acc: 0.8350\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3064 - acc: 0.8687 - val_loss: 0.3482 - val_acc: 0.8420\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3026 - acc: 0.8682 - val_loss: 0.3431 - val_acc: 0.8440\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.3036 - acc: 0.8662 - val_loss: 0.3461 - val_acc: 0.8380\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2984 - acc: 0.8703 - val_loss: 0.3477 - val_acc: 0.8470\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2995 - acc: 0.8700 - val_loss: 0.3614 - val_acc: 0.8360\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2960 - acc: 0.8686 - val_loss: 0.3494 - val_acc: 0.8410\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2957 - acc: 0.8693 - val_loss: 0.3474 - val_acc: 0.8450\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2947 - acc: 0.8687 - val_loss: 0.3557 - val_acc: 0.8340\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2913 - acc: 0.8710 - val_loss: 0.3585 - val_acc: 0.8390\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2894 - acc: 0.8743 - val_loss: 0.3544 - val_acc: 0.8410\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2865 - acc: 0.8709 - val_loss: 0.3402 - val_acc: 0.8400\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2884 - acc: 0.8708 - val_loss: 0.3528 - val_acc: 0.8460\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2864 - acc: 0.8747 - val_loss: 0.3391 - val_acc: 0.8470\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2830 - acc: 0.8773 - val_loss: 0.3456 - val_acc: 0.8410\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2849 - acc: 0.8736 - val_loss: 0.3427 - val_acc: 0.8370\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2809 - acc: 0.8748 - val_loss: 0.3516 - val_acc: 0.8450\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2821 - acc: 0.8743 - val_loss: 0.3462 - val_acc: 0.8350\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2817 - acc: 0.8748 - val_loss: 0.3496 - val_acc: 0.8380\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2753 - acc: 0.8785 - val_loss: 0.3552 - val_acc: 0.8340\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2721 - acc: 0.8794 - val_loss: 0.3506 - val_acc: 0.8440\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2722 - acc: 0.8785 - val_loss: 0.3564 - val_acc: 0.8420\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2738 - acc: 0.8772 - val_loss: 0.3595 - val_acc: 0.8400\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2697 - acc: 0.8785 - val_loss: 0.3516 - val_acc: 0.8460\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2732 - acc: 0.8796 - val_loss: 0.3624 - val_acc: 0.8430\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2699 - acc: 0.8804 - val_loss: 0.3558 - val_acc: 0.8400\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2741 - acc: 0.8774 - val_loss: 0.3554 - val_acc: 0.8380\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2696 - acc: 0.8795 - val_loss: 0.3619 - val_acc: 0.8310\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2706 - acc: 0.8799 - val_loss: 0.3594 - val_acc: 0.8370\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2653 - acc: 0.8834 - val_loss: 0.3638 - val_acc: 0.8330\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2654 - acc: 0.8834 - val_loss: 0.3882 - val_acc: 0.8330\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2645 - acc: 0.8787 - val_loss: 0.3655 - val_acc: 0.8370\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2639 - acc: 0.8817 - val_loss: 0.3605 - val_acc: 0.8310\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2660 - acc: 0.8815 - val_loss: 0.3527 - val_acc: 0.8370\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2590 - acc: 0.8822 - val_loss: 0.3585 - val_acc: 0.8390\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2605 - acc: 0.8826 - val_loss: 0.3804 - val_acc: 0.8430\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2553 - acc: 0.8864 - val_loss: 0.3778 - val_acc: 0.8400\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2532 - acc: 0.8910 - val_loss: 0.3765 - val_acc: 0.8370\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2535 - acc: 0.8875 - val_loss: 0.3870 - val_acc: 0.8280\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2532 - acc: 0.8852 - val_loss: 0.3685 - val_acc: 0.8440\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2514 - acc: 0.8885 - val_loss: 0.3845 - val_acc: 0.8440\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2520 - acc: 0.8847 - val_loss: 0.3862 - val_acc: 0.8370\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2538 - acc: 0.8858 - val_loss: 0.3740 - val_acc: 0.8370\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2491 - acc: 0.8887 - val_loss: 0.4224 - val_acc: 0.8240\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2493 - acc: 0.8878 - val_loss: 0.3895 - val_acc: 0.8370\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2455 - acc: 0.8871 - val_loss: 0.3925 - val_acc: 0.8390\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2534 - acc: 0.8863 - val_loss: 0.3845 - val_acc: 0.8420\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2511 - acc: 0.8871 - val_loss: 0.3668 - val_acc: 0.8380\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2442 - acc: 0.8913 - val_loss: 0.3719 - val_acc: 0.8390\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2396 - acc: 0.8932 - val_loss: 0.4043 - val_acc: 0.8390\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2421 - acc: 0.8932 - val_loss: 0.3698 - val_acc: 0.8460\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2466 - acc: 0.8909 - val_loss: 0.3918 - val_acc: 0.8330\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2435 - acc: 0.8893 - val_loss: 0.3989 - val_acc: 0.8400\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2409 - acc: 0.8933 - val_loss: 0.4011 - val_acc: 0.8410\n"
     ]
    }
   ],
   "source": [
    "#history = model.fit([inputs_train, queries_train], answers_train, batch_size=32, epochs=100, validation_data=([inputs_test, queries_test], answers_test))\n",
    "history = model.fit([inputs_train, queries_train], answers_train, batch_size=32, epochs=100, validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mybrandnewmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 38)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2588785e-15, 2.9219460e-15, 2.4675469e-15, 2.6234957e-15,\n",
       "       1.8284026e-15, 2.3396153e-15, 3.5231821e-15, 2.2525454e-15,\n",
       "       1.9747961e-15, 2.5935639e-15, 3.9396256e-15, 2.2929019e-15,\n",
       "       3.2575407e-15, 3.2082487e-15, 2.8868469e-15, 8.0848877e-06,\n",
       "       2.7744221e-15, 1.8075077e-15, 4.5423239e-15, 1.4052955e-15,\n",
       "       2.8729060e-15, 2.7312419e-15, 2.1349381e-15, 3.2994621e-15,\n",
       "       9.9999189e-01, 3.5153284e-15, 1.7340312e-15, 3.3040468e-15,\n",
       "       2.3915645e-15, 2.2861070e-15, 2.9147878e-15, 3.4532324e-15,\n",
       "       2.0619327e-15, 3.3544396e-15, 2.9790081e-15, 3.3928157e-15,\n",
       "       4.2264882e-15, 2.1006688e-15], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = {index: word for word, index in tokenizer.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'yes',\n",
       " 'yes']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(pred_result, axis=1)\n",
    "pred_answers = [index_word[pred] for pred in predictions]\n",
    "pred_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with a run time question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The answer should be 'yes'.\n",
    "mydata = [(my_story.split(), my_question.split(), 'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story, my_ques, my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = model.predict([my_story, my_ques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the answer corresponding to the highest predict probabilty.\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95445025"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out what's the highest predict probability.\n",
    "pred_result[0][val_max]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
